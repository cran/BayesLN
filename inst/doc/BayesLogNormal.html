<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Aldo Gardini, Carlo Trivisano and Enrico Fabrizi" />

<meta name="date" content="2023-12-04" />

<title>Bayesian Inference with Log-normal Data</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Bayesian Inference with Log-normal
Data</h1>
<h4 class="author">Aldo Gardini, Carlo Trivisano and Enrico Fabrizi</h4>
<h4 class="date">2023-12-04</h4>



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Inference under the log-normal assumption for the data looks simple
as parameters can be estimated taking the log- transform and then
working with normality of the transformed data. Estimation of
descriptors of the variable in question before transformation (such as
median, mean, quantiles, variance, etc…) involve back-transformation can
be critical as naive estimators can perform poorly. Here we focus on the
estimation of a log-normal mean and quantiles and on the prediction of
the conditional expectation in a lognormal linear and linear mixed
models. In all these cases these estimates can be defined as functionals
(involving the exp) of parameters estimated on log-transformed data. In
the first place, back-transforming involves bias whenever the
transformation is nonlinear, but this is not the only problem. In fact,
one may suppose that this inferential issue is easily overcome in the
Bayesian framework by sampling directly from the posterior distributions
of the target functional, but there can be problems with the posteriors
obtained assuming most of the priors popular in the analysis of normal
data.</p>
<p>If Bayes estimator under the quadratic loss function are to be
considered (i.e., the posterior mean), the finiteness of the posterior
moments must be assured at least up to the second order, to obtain the
posterior variance too. The existence of such posterior moments, which
is crucial to summarize the posterior distribution using squared loss,
is often taken for granted, but this may not be the case for many prior
choices. Furthermore, if estimation is performed through MCMC methods
the non-existence of posterior moments cannot be easily detected.</p>
<p>When an improper prior is fixed, a lot of care is usually taken in
the properness of the posterior distribution. Even if the distribution
is proper, it is not guaranteed that its moments are finite. This is the
case with the Bayes estimators of log-normal functionals when the
analysis is based on the choice of popular priors, both improper and
proper (like the inverse gamma for the log-scale variance). For the
estimation of the mean of a log-normal variable, this issue was first
highlighted by <span class="citation">Zellner (1971)</span> and then the
issues affecting the Bayesian estimation of the log-normal mean were
faced by <span class="citation">Fabrizi and Trivisano (2012)</span> and
<span class="citation">Fabrizi and Trivisano (2016)</span>, wherein the
log-normal linear model was considered. The core of their proposal
consists of specifying a generalized inverse Gaussian (GIG) prior for
the variance in the log-scale <span class="math inline">\(\sigma^2\)</span>. In this way, existence
conditions for the posterior moments of the target functionals to
estimate were found and a careful inferential procedure in the Bayesian
framework was proposed.</p>
<p>Functions that allows to carry out Bayesian inference for important
functionals under the log-normality assumption are included in the
<code>BayesLN</code> package. With respect to the theory covered in
Fabrizi and Trivisano (2012, 2016), the <code>BayesLN</code> package
offers tools for the estimation of quantiles <span class="citation">(Gardini, Trivisano, and Fabrizi 2020)</span> and means
under mixed models too.</p>
</div>
<div id="some-theoretical-results" class="section level2">
<h2>Some theoretical results</h2>
<p>In this section, a brief overview of the theoretical problems are
presented, followed by some key results, in order to motivate and
describe the usefulness of the <code>R</code> functions implemented in
the package.</p>
<div id="model-with-only-fixed-effects" class="section level3">
<h3>Model with only fixed effects</h3>
<p>The conditional estimation problem is directly faced, since the
unconditional case can be easily deduced as a special case.</p>
<p>In this context, a random sample of size <span class="math inline">\(n\)</span> is observed: <span class="math display">\[\begin{equation*}
(y_i,\mathbf{x}_i),\ i=1\dots n;
\end{equation*}\]</span> where <span class="math inline">\(\mathbf{x}_i\)</span> is a vector containing the
values of the <span class="math inline">\(p\)</span> covariates that are
related to the <span class="math inline">\(i\)</span>-th unit. These
vectors are stored as rows of the usual design matrix <span class="math inline">\(\mathbf{X}\in\mathbb{R}^{n\times p}\)</span>.
Besides, the vector of the logarithmic transformation of the response
variable is <span class="math inline">\(\mathbf{w}=\log(\mathbf{y})\)</span>. Finally, the
following distributional assumption is fixed: <span class="math display">\[\begin{equation}\label{eq:ass_reg}
y_i|\mathbf{x}_i,\boldsymbol{\beta},\sigma^2\sim
\log\mathcal{N}\left(\mathbf{x}_i^T\boldsymbol{\beta},\sigma^2\right),\
i=1,\dots n,
\end{equation}\]</span> where <span class="math inline">\(\boldsymbol{\beta}=(\beta_0,...,\beta_{p-1})\)</span>
is the vector of coefficients.</p>
<p>To complete the inferential setting, the improper flat prior is
assumed for the regression coefficients and a generalized inverse
Gaussian (GIG) prior is fixed for the variance in the log scale <span class="math inline">\(\sigma^2\)</span>: <span class="math display">\[\begin{align}
&amp;\boldsymbol{\beta}\propto 1,\\
&amp;\sigma^2\sim GIG(\lambda, \delta,
\gamma)\label{eq:priors_model_GIG};
\end{align}\]</span> where <span class="math inline">\(\lambda\in
\mathbb{R}\)</span>, <span class="math inline">\(\delta\in
\mathbb{R}^+\)</span> and <span class="math inline">\(\gamma\in
\mathbb{R}^+\)</span> are the hyperparameter to specify.</p>
<p>The inferential questions that will be answered involve two basic
functionals of the log-normal theory:</p>
<ul>
<li>the conditional mean at a given a point <span class="math inline">\(\tilde{\mathbf{x}}\in\mathbb{R}^{q}\)</span> of
the covariate space:</li>
</ul>
<p><span class="math display">\[\begin{equation}
\theta_m(\tilde{\mathbf{x}})=\mathbb{E}\left[\tilde{y}|\tilde{\mathbf{x}}\right]=\exp\left\{\tilde{\mathbf{x}}^T\boldsymbol{\beta}+\frac{\sigma^2}{2}
\right\};
\end{equation}\]</span> and the function <code>LN_MeanReg()</code>
allows to make inference on this quantity;</p>
<ul>
<li>the <span class="math inline">\(p\)</span>-th quantile at a given a
point <span class="math inline">\(\tilde{\mathbf{x}}\in\mathbb{R}^{q}\)</span> of
the covariate space:</li>
</ul>
<p><span class="math display">\[\begin{equation}
\theta_p(\tilde{\mathbf{x}})=\mathbb{Q}_p\left[\tilde{y}|\tilde{\mathbf{x}}\right]=\exp\left\{\tilde{\mathbf{x}}^T\boldsymbol{\beta}+\Phi^{-1}(p)\sigma
\right\},
\end{equation}\]</span> and the function <code>LN_QuantReg()</code> can
be used to obtain posterior summaries for this quantity.</p>
<p>It is possible to prove that the posterior moments of these
functionals are finite up to order <span class="math inline">\(r\)</span> if the following conditions on the tail
parameter <span class="math inline">\(\gamma\)</span> of the GIG prior
holds.</p>
<ul>
<li><span class="math inline">\(\mathbb{E}[\theta_m(\tilde{\mathbf{x}})^r|\mathbf{y}]&lt;\infty\)</span>
if <span class="math inline">\(\gamma&gt;r+r^2\tilde{\mathbf{x}}^T(\mathbf{X}^T\mathbf{X})^{-1}\tilde{\mathbf{x}}\)</span>;</li>
<li><span class="math inline">\(\mathbb{E}[\theta_p(\tilde{\mathbf{x}})^r|\mathbf{y}]&lt;\infty\)</span>
if <span class="math inline">\(\gamma&gt;r^2\tilde{\mathbf{x}}^T(\mathbf{X}^T\mathbf{X})^{-1}\tilde{\mathbf{x}}\)</span>.</li>
</ul>
<p>In the proposed software implementation of the methodologies, the
conditions on the parameter <span class="math inline">\(\gamma\)</span>
are evaluated with <span class="math inline">\(r=3\)</span> to set the
hyperparameter value, in order to assure the stable existence of the
posterior variance.</p>
<p>It is useful to remark that in case of unconditional estimation, the
previous target quantities and the related conditions reduce to the
following ones:</p>
<ul>
<li>The unconditional mean is <span class="math inline">\(\theta_m=\exp\{\beta_0+\frac{\sigma^2}{2}\}\)</span>
and the moments are defined up to order <span class="math inline">\(r\)</span> if <span class="math inline">\(\gamma&gt;r+\frac{r^2}{n}\)</span>. The function
<code>LN_Mean()</code> can be used for this particular case.</li>
<li>The unconditional quantile is <span class="math inline">\(\theta_p=\exp\{\beta_0+\Phi^{-1}(p)\sigma\}\)</span>,
the moments are defined up to order <span class="math inline">\(r\)</span> if <span class="math inline">\(\gamma&gt;\frac{r^2}{n}\)</span> and the function
<code>LN_Quan()</code> can be used.</li>
</ul>
<p>The last aspect to determine is the hyperparameters specification.
For all the <code>R</code> functions related to these quantities, two
different strategies are proposed and can be selected through the
<code>method</code> argument:</p>
<ul>
<li>If a weakly informative prior for the variance is desired, the
(default) <code>&quot;weak_inf&quot;</code> option can be chosen. In this way, it
has been proved that credibility intervals with good frequentist
properties are obtained <span class="citation">(Fabrizi and Trivisano
2012)</span>.</li>
<li>If the point estimation is desired, optimal-MSE procedures are
implemented too and can be set using the <code>&quot;optimal&quot;</code> option.
For details of the setting related to the mean estimation process see
<span class="citation">Fabrizi and Trivisano (2012)</span> and <span class="citation">Fabrizi and Trivisano (2016)</span>. For quantiles a
numerical procedure is called.</li>
</ul>
</div>
<div id="conditional-means-estimation-under-linear-mixed-models" class="section level3">
<h3>Conditional means estimation under linear mixed models</h3>
<p>In this case we are considering a vector of responses <span class="math inline">\(\mathbf{y}\in\mathbb{R}^n\)</span> and the
assumption of log-normality for the response means analysing the
log-transformed vector <span class="math inline">\(\mathbf{w}=\log
\mathbf{y}\)</span> as normally distributed. The classical formulation
of the model is: <span class="math display">\[\begin{equation}
\mathbf{w}=
\mathbf{X}\boldsymbol{\beta}+\mathbf{Zu}+\boldsymbol{\varepsilon}.
\end{equation}\]</span> The coefficients of the fixed effects are in the
vector <span class="math inline">\(\boldsymbol{\beta}\in\mathbb{R}^p\)</span>,
whereas <span class="math inline">\(\mathbf{u}\in\mathbb{R}^m\)</span>
is the vector of random effects and <span class="math inline">\(\boldsymbol{\varepsilon}\in\mathbb{R}^{n}\)</span>
is the vector of residuals. The design matrices are <span class="math inline">\(\mathbf{X}\in\mathbb{R}^{n\times p}\)</span>, that
is assumed to be full rank in order to guarantee the existence of <span class="math inline">\((\mathbf{X}^T\mathbf{X})^{-1}\)</span>, and <span class="math inline">\(\mathbf{Z}\in\mathbb{R}^{n\times m}\)</span>. The
following Bayesian hierarchical model is studied:</p>
<p><span class="math display">\[\begin{equation}\label{eq:mod_mix}
\begin{aligned}
&amp;\mathbf{w}|\mathbf{u}, \boldsymbol{\beta}, \sigma^2\sim
\mathcal{N}_n\left(\mathbf{X}\boldsymbol{\beta}+\mathbf{Zu},
\mathbf{I}_n\sigma^2 \right);\\
&amp;\mathbf{u}|\tau^2_1,...,\tau^2_q\sim\mathcal{N}_m\left(\mathbf{0},
\mathbf{D}\right),\  \mathbf{D}=\oplus^q_{s=1}\mathbf{I}_{m_s}\tau_s^2;\\
&amp;(\boldsymbol{\beta},\sigma^2)\sim p(\boldsymbol{\beta},\sigma^2);\\
&amp;\boldsymbol{\tau}^2\sim p(\tau_1^2,...,\tau_q^2).
\end{aligned}
\end{equation}\]</span></p>
<p>Since <span class="math inline">\(q\)</span> random factors are
considered, <span class="math inline">\(q\)</span> different variances
related to the random components <span class="math inline">\(\boldsymbol{\tau}^2=(\tau^2_1,...,\tau^2_q)\)</span>
are included in the model. Therefore, it is possible to split the vector
of random effects in <span class="math inline">\(\mathbf{u}=[\mathbf{u}_1^T,...,\mathbf{u}_s^T,...,\mathbf{u}_q^T]^T\)</span>,
where <span class="math inline">\(\mathbf{u}_s\in\mathbb{R}^{m_s}\)</span> with
<span class="math inline">\(\sum_{s=1}^q m_s=m\)</span>. The design
matrix of the random effects might be partitioned too: <span class="math inline">\(\mathbf{Z}=[\mathbf{Z}_1\cdots
\mathbf{Z}_s\cdots\mathbf{Z}_q]\)</span>.</p>
<p>The function <code>LN_hierarchical()</code> allows the user to make
inference on the desired log-normal linear mixed model by sampling from
the posterior distributions through a Gibbs sampler. The model equation
need to be given to the <code>formula_lme</code> argument using the same
syntax as the <code>lmer()</code> function of the <code>lme4</code>
package <span class="citation">(Bates et al. 2015)</span>.</p>
<p>In practice, the interpretable outputs are usually provided in the
original data scale, back-transforming the results obtained estimating
the previous model. Exploiting the properties of the log-normal
distribution, the following quantities can be of interest:</p>
<ul>
<li>the conditioned expectation of the observation <span class="math inline">\(\tilde{y}\)</span> given the random effects and
the covariate patterns <span class="math inline">\(\tilde{\mathbf{x}},\
\tilde{\mathbf{z}}\)</span> (quantity that could be also labelled as
subject-specific expectation). It is defined as:</li>
</ul>
<p><span class="math display">\[\begin{equation}
\theta_c(\tilde{\mathbf{x}},\tilde{\mathbf{z}})=\mathbb{E}\left[\tilde{y}|\mathbf{u},\tilde{\mathbf{x}},\tilde{\mathbf{z}}\right]=\exp\left\{\tilde{\mathbf{x}}^T\boldsymbol{\beta}+\tilde{\mathbf{z}}^T\mathbf{u}+\frac{\sigma^2}{2}
\right\},
\end{equation}\]</span></p>
<ul>
<li>if the random effects are ignored and they are integrated out, then
the conditioned expectation of interest is:</li>
</ul>
<p><span class="math display">\[\begin{equation}\label{eq:avg_marg}
\theta_m(\tilde{\mathbf{x}})=\mathbb{E}\left[\tilde{y}|\tilde{\mathbf{x}}\right]=\exp\left\{\tilde{\mathbf{x}}^T\boldsymbol{\beta}+\frac{1}{2}\left(\sigma^2+\sum_{s=1}^q
\tau_s^2\right) \right\};
\end{equation}\]</span></p>
<ul>
<li>the posterior predictive distribution <span class="math inline">\(p(\tilde{y}|\mathbf{y})\)</span> and its posterior
moments is a further quantity that might be investigated.</li>
</ul>
<p>The argument <code>functional</code> of the
<code>LN_hierarchical()</code> function let the user specify the kind of
functionals for which the posterior distribution is of interest: the
posterior of <span class="math inline">\(\theta_c(\tilde{\mathbf{x}},\tilde{\mathbf{z}})\)</span>
is obtained by specifying <code>&quot;Subject&quot;</code>, <span class="math inline">\(\theta_m(\tilde{\mathbf{x}})\)</span> with
<code>&quot;Marginal&quot;</code> and the posterior predictive distribution with
<code>&quot;PostPredictive&quot;</code>. Moreover, the argument
<code>data_pred</code> allow to provide a data frame containing the
desired covariate points for which the target quantities need to be
computed.</p>
<p>As in the previous section, independent GIG priors are adopted for
the variance components: <span class="math display">\[\begin{equation}
p(\sigma^2)\sim GIG(\lambda_\sigma,\delta_\sigma,\gamma_\sigma);\ \
p(\tau_s^2)\sim GIG(\lambda_{\tau,s},\delta_{\tau,s} ,\gamma_{\tau,s}),\
\forall s.
\end{equation}\]</span> Moreover, it is possible to prove that the tail
parameter <span class="math inline">\(\gamma\)</span> is involved again
in the existence conditions for the posterior moments of the target
quantities defined above. In particular:</p>
<ul>
<li><span class="math inline">\(\mathbb{E}\left[\theta_c^r(\tilde{\mathbf{x}},\tilde{\mathbf{z}})|\mathbf{w}\right]\)</span>
exists if <span class="math inline">\(\gamma_{\sigma}^2&gt;r+r^2\tilde{\mathbf{x}}^T\left(\mathbf{X}^T\mathbf{X}\right)^{-1}\tilde{\mathbf{x}}\)</span>;</li>
<li><span class="math inline">\(\mathbb{E}\left[\theta_m^r(\tilde{\mathbf{x}})|\mathbf{w}\right]\)</span>
exists if <span class="math inline">\(\gamma_{\sigma}^2&gt;r+r^2\tilde{\mathbf{x}}^T\left(\mathbf{X}^T\mathbf{X}\right)^{-1}\tilde{\mathbf{x}}\)</span>
and <span class="math inline">\(\gamma^2_{\tau,s}&gt;r+r^2\tilde{\mathbf{x}}_{o}^T\mathbf{L}_s\tilde{\mathbf{x}}_{o},\
\forall s\)</span>;</li>
<li><span class="math inline">\(\mathbb{E}\left[\tilde{y}^r|\mathbf{y}\right]\)</span>
exists if <span class="math inline">\(\gamma_{\sigma}^2&gt;r^2+r^2\tilde{\mathbf{x}}^T\left(\mathbf{X}^T\mathbf{X}\right)^{-1}\tilde{\mathbf{x}}\)</span>.</li>
</ul>
<p>If the first and the latter conditions are equal to the ones stated
in the previous section and only the tail parameter of the prior for
<span class="math inline">\(\sigma^2\)</span> is involved, the existence
condition for the posterior moments of <span class="math inline">\(\theta_m(\tilde{\mathbf{x}})\)</span> requires a
constraint on <span class="math inline">\(\gamma_{\tau,s}\)</span> too.
This expression is function of the the matrix <span class="math inline">\(\mathbf{L}_s\in\mathbb{R}^{p\times p}\)</span>:
its entries are all 0s with the exception of the first <span class="math inline">\(l \times l\)</span> square block <span class="math inline">\(\mathbf{L}_{s;1,1}\)</span>, where <span class="math inline">\(l=p-\text{rank}\{
\mathbf{X}^T\left(\mathbf{I}-\mathbf{P_Z} \right)\mathbf{X}\}\)</span>.
It coincides with the number of variables of <span class="math inline">\(\mathbf{X}\)</span> that are included in <span class="math inline">\(\mathbf{Z}\)</span> too. Furthermore, to simplify
the final form of the result, it is useful to place the columns related
to these variables as first <span class="math inline">\(l\)</span>
columns of the <span class="math inline">\(\mathbf{X}_o\)</span>,
without loss of generality. As a consequence, the matrix <span class="math inline">\(\mathbf{L}_{s;1,1}\)</span> coincides with the
inverse of the upper left <span class="math inline">\(l \times
l\)</span> block on the diagonal of the matrix <span class="math inline">\(\mathbf{X}_o^T\left(\mathbf{Z}(\mathbf{Z}^T\mathbf{Z})^{-}\mathbf{C}_s
(\mathbf{Z}^T\mathbf{Z})^{-}\mathbf{Z}^T\right)\mathbf{X}_o\)</span>,
where <span class="math inline">\(\mathbf{C}_s\)</span> is the null
matrix with the exception of <span class="math inline">\(\mathbf{I}_{m_s}\)</span> as block on the diagonal
in correspondence to the <span class="math inline">\(s\)</span>-th
variance component of the random effect. To complete the notation, <span class="math inline">\(\tilde{\mathbf{x}}_{o}\)</span> is the covariate
pattern of the observation to estimate that is ordered coherently with
respect to <span class="math inline">\(\mathbf{X}_o\)</span>.</p>
<p>Because of the non-intuitive expressions of the existence conditions,
the function <code>LN_hier_existence()</code> is implemented to compute
them. This routine is called by the function
<code>LN_hierarchical()</code> to fix the values of the hyperparameters
in order to fulfil the more restrictive existence condition for the
functionals of interest, if the default priors are desired. To specify
different priors, the arguments <code>par_tau</code> and
<code>par_sigma</code> can be used.</p>
<p>Otherwise, if the proposed prior specification is adopted, the key
concepts of the strategy can be synthesized as follows:</p>
<ul>
<li>the hyperparameters of all the priors are the same, to preserve the
prior balance among the different variance components;</li>
<li>as tail parameter <span class="math inline">\(\gamma\)</span>, the
more restrictive condition is evaluated replacing <span class="math inline">\(r\)</span> with the specified
<code>order_moment</code> (default 2) plus 1;</li>
<li>to obtain uniform marginal priors for the intraclass correlation
coefficients, it is fixed <span class="math inline">\(\lambda=1\)</span>
and <span class="math inline">\(\delta=\varepsilon=0.01\)</span>.</li>
</ul>
</div>
</div>
<div id="real-data-applications" class="section level2">
<h2>Real data applications</h2>
<p>To show how the functions of the package work and to briefly
illustrate the produced outputs, some real data application are
presented in this section.</p>
<div id="unconditional-estimation" class="section level3">
<h3>Unconditional estimation</h3>
<p>In environmental monitoring, it is common to deal with small datasets
containing observations of pollutant concentrations and for which the
log-normality assumption appears to be appropriate. In these
applications, it is important to provide both point estimates and
intervals, that constitutes the so-called confidence limits. A popular
example included in <span class="citation">USEPA (2009)</span> is faced:
it consists of a small sample (<span class="math inline">\(n=8\)</span>)
of chrysene concentrations (ppb) obtained from two background wells. The
vector of observations is already included in the package and is named
<code>EPA09</code>.</p>
<p>First, the mean estimation problem is faced and the function
<code>LN_Mean()</code> is used. If a point estimate is desired, the
advise is to use the <code>&quot;optimal&quot;</code> prior setting. Since the
observations are not already log-transformed, the argument
<code>x_transf</code> is set as <code>FALSE</code>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;EPA09&quot;</span>)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="co"># Bayes estimator under relative quadratic loss and optimal prior setting</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="fu">LN_Mean</span>(<span class="at">x =</span> EPA09, <span class="at">x_transf =</span> <span class="cn">FALSE</span>, <span class="at">method =</span> <span class="st">&quot;optimal&quot;</span>, <span class="at">CI =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co">#&gt; $Prior_Parameters</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co">#&gt; lambda  delta  gamma </span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="co">#&gt; -3.800  0.010  2.031 </span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="co">#&gt; $Posterior_Parameters</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co">#&gt; lambda  alpha  delta   beta     mu </span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="co">#&gt; -7.300  7.000  0.587  4.000  2.509 </span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="co">#&gt; $LogN_Par_Post</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="co">#&gt;             Mean         Var    p=0.05    p=0.50    p=0.95</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co">#&gt; xi     2.5085773 0.025427261 2.2479885 2.5085773 2.7691661</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a><span class="co">#&gt; sigma2 0.2034181 0.006442247 0.1088789 0.1865022 0.3542689</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a><span class="co">#&gt; $Post_Estimates</span></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a><span class="co">#&gt;          Mean     S.d.</span></span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a><span class="co">#&gt; [1,] 13.79142 2.352631</span></span></code></pre></div>
<p>The output reports the prior parameters for the variance <span class="math inline">\(\sigma^2\sim GIG(\lambda, \delta, \gamma)\)</span>
and the 5 parameters that characterize the posterior distribution of the
log-normal mean <span class="math inline">\(\theta_m\)</span>, i.e. a
Generalized Hyperbolic distribution (see <span class="citation">Fabrizi
and Trivisano (2012)</span> for more methodological details). Then, the
basic summaries of the posterior distributions of the log-normal
parameters are reported (<code>xi</code> is the log-scale mean and
<code>sigma2</code> the log-scale variance). Finally, the posterior mean
<span class="math inline">\(\mathbb{E}[\theta_m|\mathbf{y}]\)</span> and
the posterior standard deviation of the target quantity are reported
(note that these values are obtained in closed form, without MC
simulations).</p>
<p>On the other hand, if the interval estimate is required, it is
advisable to use the weakly informative (<code>&quot;weak_inf&quot;</code>) prior
setting, specify the desired credibility level <code>alpha_CI</code> and
select the type of interval: it is possible to obtain as output the
usual two sided interval (<code>&quot;two-sided&quot;</code>), the lower credible
limit (<code>&quot;LCL&quot;</code>) and the upper credible limit
(<code>&quot;UCL&quot;</code>). The last two interval kinds are often required in
environmental problems to estimate pollutants legal limits. For example,
the <span class="math inline">\(95\%\)</span> UCL can be estimated as
follows.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">LN_Mean</span>(<span class="at">x =</span> EPA09, <span class="at">x_transf =</span> <span class="cn">FALSE</span>, <span class="at">method =</span> <span class="st">&quot;weak_inf&quot;</span>, <span class="at">alpha_CI =</span> <span class="fl">0.05</span>, <span class="at">type_CI =</span> <span class="st">&quot;UCL&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="co">#&gt; $Prior_Parameters</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co">#&gt; lambda  delta  gamma </span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co">#&gt;  0.000  0.010  2.031 </span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co">#&gt; $Posterior_Parameters</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co">#&gt; lambda  alpha  delta   beta     mu </span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="co">#&gt; -3.500  7.000  0.587  4.000  2.509 </span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co">#&gt; $LogN_Par_Post</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="co">#&gt;             Mean        Var    p=0.05    p=0.50    p=0.95</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="co">#&gt; xi     2.5085773 0.04906591 2.1479285 2.5085773 2.8692261</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="co">#&gt; sigma2 0.3925273 0.03930270 0.1748106 0.3462637 0.7712068</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a><span class="co">#&gt; $Post_Estimates</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a><span class="co">#&gt;          Mean     S.d.</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a><span class="co">#&gt; [1,] 15.42667 4.241931</span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a><span class="co">#&gt; $Interval</span></span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a><span class="co">#&gt; Lower limit Upper limit </span></span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a><span class="co">#&gt;      0.0000     22.9175</span></span></code></pre></div>
<p>The interval is added to the previous output, noting that the
posterior quantiles required to produce the interval are obtained by
simulation.</p>
<p>The same procedures can be implemented also if the interest is in
estimating a quantile <span class="math inline">\(\theta_p\)</span>
under the log-normality assumption. For example, if the target is
quantile <span class="math inline">\(p=0.95\)</span>, to find an optimal
point estimate it is possible to use the following command.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">LN_Quant</span>(<span class="at">x =</span> EPA09, <span class="at">x_transf =</span> <span class="cn">FALSE</span>, <span class="at">quant =</span> <span class="fl">0.95</span>, <span class="at">method =</span> <span class="st">&quot;optimal&quot;</span>, <span class="at">CI =</span> <span class="cn">FALSE</span>)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="co">#&gt; The Bayes estimator under quadratic loss is employed</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co">#&gt; $Quantile</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co">#&gt; [1] 0.95</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="co">#&gt; $Parameters</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co">#&gt;           lambda delta  gamma    mu  beta</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="co">#&gt; prior        0.0 1.000  4.609    NA    NA</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="co">#&gt; posterior   -3.5 0.686 13.036 2.509 4.652</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co">#&gt; $LogN_Par_Post</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="co">#&gt;             Mean        Var    p=0.05    p=0.50    p=0.95</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="co">#&gt; xi     2.5085773 0.03841293 2.1874892 2.5085773 2.8296654</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="co">#&gt; sigma2 0.3073035 0.01025415 0.1750871 0.2903003 0.4961176</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="co">#&gt; $Post_Estimates</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="co">#&gt;          Mean    S.d.</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="co">#&gt; [1,] 31.18081 8.25687</span></span></code></pre></div>
<p>The output is similar to the one printed for the mean <span class="math inline">\(\theta_m\)</span> and in this case the posterior
mean and standard deviation of the desired quantile <span class="math inline">\(\theta_p\)</span> are reported. To compute an
interval estimate, the function can be used as showed for
<code>LN_Mean()</code>.</p>
</div>
<div id="log-normal-regression" class="section level3">
<h3>Log-normal regression</h3>
<p>The presented methods can be useful in predicting conditioned means
under a log-normal linear model. The function <code>LN_MeanReg()</code>
receives as input the vector <code>y</code> containing the observations
of the response variable and the design matrix <code>X</code>. A matrix
<code>Xtilde</code>, containing the covariate patterns for which a
prediction is required, must be provided too. Likewise the unconditional
estimation problem, it is possible to specify both an optimal prior
setting and a weakly informative one.</p>
<p>As illustrative example, the same data used in <span class="citation">Fabrizi and Trivisano (2016)</span> are considered,
loading the <code>&quot;fatigue&quot;</code> dataset. Results for the weakly
informative setting are reported.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;fatigue&quot;</span>)</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co"># Design matrices</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>Xtot <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, <span class="fu">log</span>(fatigue<span class="sc">$</span>stress), <span class="fu">log</span>(fatigue<span class="sc">$</span>stress)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>X <span class="ot">&lt;-</span> Xtot[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">13</span>,<span class="dv">22</span>),]</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>y <span class="ot">&lt;-</span> fatigue<span class="sc">$</span>cycle[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">13</span>,<span class="dv">22</span>)]</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>Xtilde <span class="ot">&lt;-</span> Xtot[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">13</span>,<span class="dv">22</span>),] <span class="co"># units to predict</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="co">#Estimation</span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a><span class="fu">LN_MeanReg</span>(<span class="at">y =</span> y,</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>           <span class="at">X =</span> X, <span class="at">Xtilde =</span> Xtilde,</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>           <span class="at">method =</span> <span class="st">&quot;weak_inf&quot;</span>, <span class="at">y_transf =</span> <span class="cn">FALSE</span>)</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a><span class="co">#&gt; $Prior_Parameters</span></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a><span class="co">#&gt; lambda  delta  gamma </span></span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a><span class="co">#&gt;  0.000  0.010  2.823 </span></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a><span class="co">#&gt; $Posterior_Parameters</span></span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a><span class="co">#&gt;      lambda  alpha delta  beta     mu</span></span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a><span class="co">#&gt; [1,]     -8 19.573 1.034 3.167  9.188</span></span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a><span class="co">#&gt; [2,]     -8 19.573 1.034 3.167 10.791</span></span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a><span class="co">#&gt; [3,]     -8 19.573 1.034 3.167 11.507</span></span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a><span class="co">#&gt; $Sigma2</span></span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a><span class="co">#&gt;             Mean        Var       q5       q50       q95</span></span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a><span class="co">#&gt; sigma2 0.3887769 0.01556038 0.229139 0.3668367 0.6229102</span></span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a><span class="co">#&gt; $Coefficients</span></span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a><span class="co">#&gt;           Mean     S.d.         q2.5         q25       q50       q75     q97.5</span></span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a><span class="co">#&gt; [1,] 254.18651 102.7014   51.4762078  186.910185 253.67342 321.55286 457.72000</span></span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a><span class="co">#&gt; [2,] -99.55638  44.0258 -186.6546203 -128.438923 -99.77860 -70.86023 -11.99868</span></span>
<span id="cb4-33"><a href="#cb4-33" tabindex="-1"></a><span class="co">#&gt; [3,]  10.12994   4.7291    0.8160653    7.015753  10.11528  13.23341  19.48882</span></span>
<span id="cb4-34"><a href="#cb4-34" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb4-35"><a href="#cb4-35" tabindex="-1"></a><span class="co">#&gt; $Post_Estimates</span></span>
<span id="cb4-36"><a href="#cb4-36" tabindex="-1"></a><span class="co">#&gt;           Mean     S.d.</span></span>
<span id="cb4-37"><a href="#cb4-37" tabindex="-1"></a><span class="co">#&gt; [1,]  11225.41  2233.33</span></span>
<span id="cb4-38"><a href="#cb4-38" tabindex="-1"></a><span class="co">#&gt; [2,]  55740.11 11089.67</span></span>
<span id="cb4-39"><a href="#cb4-39" tabindex="-1"></a><span class="co">#&gt; [3,] 114072.47 22695.08</span></span>
<span id="cb4-40"><a href="#cb4-40" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb4-41"><a href="#cb4-41" tabindex="-1"></a><span class="co">#&gt; $Interval</span></span>
<span id="cb4-42"><a href="#cb4-42" tabindex="-1"></a><span class="co">#&gt;           low        up</span></span>
<span id="cb4-43"><a href="#cb4-43" tabindex="-1"></a><span class="co">#&gt; [1,]  7577.57  16339.36</span></span>
<span id="cb4-44"><a href="#cb4-44" tabindex="-1"></a><span class="co">#&gt; [2,] 37569.54  80715.74</span></span>
<span id="cb4-45"><a href="#cb4-45" tabindex="-1"></a><span class="co">#&gt; [3,] 76890.90 165529.44</span></span></code></pre></div>
<p>For each one of the points for which a prediction is required, the
summaries of the posterior distributions are reported:
<code>$Sigma2</code> represents the variance in the log scale, whereas
the <code>$Coefficients</code> reports the summaries of the vector of
coefficients <span class="math inline">\(\boldsymbol{\beta}\)</span>.</p>
</div>
<div id="random-coefficient-model" class="section level3">
<h3>Random coefficient model</h3>
<p>As last example, the estimation of log-normal linear mixed model is
presented. The analysed dataset is due to <span class="citation">Gibson
and Wu (2013)</span> and consists of a two-conditions repeated measure
collection of observations of the time (in milliseconds) required to
read the head noun of a Chinese clause. The following model is
specified: <span class="math display">\[\begin{equation}
w_{ijk}=\log(y_{ijk})=\beta_0+\beta_1 x_{i}+u_j+v_k+\varepsilon_{ijk},
\end{equation}\]</span> where <span class="math inline">\(y_{ijk}\)</span> is the reading time observed for
subject <span class="math inline">\(j=1,...,37\)</span>, reading item
<span class="math inline">\(k=1,...,15\)</span> and condition <span class="math inline">\(i=1,2\)</span>. Moreover, it is fixed <span class="math inline">\(x_i=-1\)</span> in case of subject relative, and
<span class="math inline">\(x_i=1\)</span> for object relative
condition.</p>
<p>The goal of the analysis is to predict the expectation conditioned on
<span class="math inline">\(x_i\)</span> and marginalized with respect
both the random effect: <span class="math display">\[\begin{equation}
\theta_m(x_i=\pm
1)=\exp\left\{\beta_0\pm\beta_1+\frac{\tau^2_u+\tau^2_v+\sigma^2}{2}
\right\}.
\end{equation}\]</span> Moreover, the expectation specific of a
particular subject and item might be of interest too: <span class="math display">\[\begin{equation}
\theta_c(x_i,u_j,v_k)=\exp\left\{\beta_0+x_i\beta_1+u_j+v_k+\frac{\sigma^2}{2}
\right\},
\end{equation}\]</span></p>
<p>As example, the prediction of these quantities for both the values of
the covariate <span class="math inline">\(x_i\)</span> related to
subject <span class="math inline">\(12\)</span> and item <span class="math inline">\(8\)</span> are desired. A new
<code>data.frame</code> containing the desired covariate patterns must
be created.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Load the dataset included in the package </span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;ReadingTime&quot;</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co"># Define data.frame containing the covariate patterns to investigate</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>data_pred_new <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">so=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>), <span class="at">subj=</span><span class="fu">factor</span>(<span class="dv">12</span>), <span class="at">item=</span><span class="fu">factor</span>(<span class="dv">8</span>))</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co"># Model estimation </span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>Mod_est_RT <span class="ot">&lt;-</span> <span class="fu">LN_hierarchical</span>(<span class="at">formula_lme =</span> log_rt <span class="sc">~</span> so <span class="sc">+</span>(<span class="dv">1</span><span class="sc">|</span>subj)<span class="sc">+</span>(<span class="dv">1</span><span class="sc">|</span>item), </span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>                              <span class="at">data_lme =</span> ReadingTime, <span class="at">data_pred =</span> data_pred_new, </span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>                              <span class="at">functional =</span> <span class="fu">c</span>(<span class="st">&quot;Marginal&quot;</span>, <span class="st">&quot;Subject&quot;</span>), </span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>                              <span class="at">nsamp =</span> <span class="dv">25000</span>, <span class="at">burnin =</span> <span class="dv">5000</span>, <span class="at">n_thin =</span> <span class="dv">5</span>)</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="co">#&gt; ----------:10.0</span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a><span class="co">#&gt; ----------:20.0</span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="co">#&gt; ----------:30.0</span></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="co">#&gt; ----------:40.0</span></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a><span class="co">#&gt; ----------:50.0</span></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a><span class="co">#&gt; ----------:60.0</span></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a><span class="co">#&gt; ----------:70.0</span></span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a><span class="co">#&gt; ----------:80.0</span></span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a><span class="co">#&gt; ----------:90.0</span></span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a><span class="co">#&gt; ----------:100.0</span></span></code></pre></div>
<p>As hinted before, the same priors for all the variance components are
specified, choosing the most restrictive value for the parameter <span class="math inline">\(\gamma\)</span> (i.e. the highest one). To check
the values, the element <code>$par_prior</code> of the output can be
printed.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Prior parameters</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>Mod_est_RT<span class="sc">$</span>par_prior</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="co">#&gt;                       lambda delta    gamma</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co">#&gt; sigma2                     1  0.01 2.433771</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co">#&gt; tau2_subj.(Intercept)      1  0.01 2.433771</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co">#&gt; tau2_item.(Intercept)      1  0.01 2.433771</span></span></code></pre></div>
<p>The <code>$samples</code> element is an object of class
<code>mcmc</code> containing the samples drown from the posterior
distributions of the model parameters and of the target functionals. The
usual tools provided by the <code>coda</code> package <span class="citation">(Plummer et al. 2006)</span> can be used to explore
them. For example, the chains convergence can be explored plotting the
traceplots.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># coda package</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="fu">library</span>(coda)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co"># Traceplots model parameters</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>oldpar <span class="ot">&lt;-</span> <span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="fu">traceplot</span>(Mod_est_RT<span class="sc">$</span>samples<span class="sc">$</span>par[, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>])</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">par</span>(oldpar)</span></code></pre></div>
<p>Finally, the <code>$summaries</code> part contains the summary
statistics of the posterior distributions of the parameters and the
functionals required. It is possible to isolate the outputs related to
the latter as follows.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Posterior summaries</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>Mod_est_RT<span class="sc">$</span>summaries<span class="sc">$</span>marg</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co">#&gt;               Mean     SD Naive SE    2.5%     25%     50%     75%   97.5%</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="co">#&gt; Marginal 1 541.830 43.121    0.682 465.033 512.820 539.320 567.982 632.149</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="co">#&gt; Marginal 2 504.295 40.242    0.636 432.134 477.225 501.332 528.268 595.054</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co">#&gt;               N_eff</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a><span class="co">#&gt; Marginal 1 1412.456</span></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="co">#&gt; Marginal 2 1338.485</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>Mod_est_RT<span class="sc">$</span>summaries<span class="sc">$</span>subj</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a><span class="co">#&gt;            Mean      SD Naive SE     2.5%      25%      50%      75%    97.5%</span></span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a><span class="co">#&gt; Subj 1 1490.443 224.957    3.557 1084.054 1335.929 1471.903 1630.183 1972.834</span></span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a><span class="co">#&gt; Subj 2 1387.360 210.751    3.332 1012.509 1240.606 1367.927 1518.081 1845.367</span></span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a><span class="co">#&gt;           N_eff</span></span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a><span class="co">#&gt; Subj 1 4274.405</span></span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a><span class="co">#&gt; Subj 2 4262.111</span></span></code></pre></div>
</div>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="unnumbered">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-lme" class="csl-entry">
Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015.
<span>“Fitting Linear Mixed-Effects Models Using <span class="nocase">lme4</span>.”</span> <em>Journal of Statistical
Software</em> 67 (1): 1–48. <a href="https://doi.org/10.18637/jss.v067.i01">https://doi.org/10.18637/jss.v067.i01</a>.
</div>
<div id="ref-fabrizi2012bayes" class="csl-entry">
Fabrizi, Enrico, and Carlo Trivisano. 2012. <span>“Bayesian Estimation
of Log-Normal Means with Finite Quadratic Expected Loss.”</span>
<em>Bayesian Analysis</em> 7 (4): 975–96.
</div>
<div id="ref-fabrizi2016bayesian" class="csl-entry">
———. 2016. <span>“Bayesian Conditional Mean Estimation in Log-Normal
Linear Regression Models with Finite Quadratic Expected Loss.”</span>
<em>Scandinavian Journal of Statistics</em> 43 (4): 1064–77.
</div>
<div id="ref-gardini2020bayesian" class="csl-entry">
Gardini, Aldo, Carlo Trivisano, and Enrico Fabrizi. 2020.
<span>“Bayesian Inference for Quantiles of the Log-Normal
Distribution.”</span> <em>Biometrical Journal</em>.
</div>
<div id="ref-gibson2013processing" class="csl-entry">
Gibson, Edward, and H-H Iris Wu. 2013. <span>“Processing Chinese
Relative Clauses in Context.”</span> <em>Language and Cognitive
Processes</em> 28 (1-2): 125–55.
</div>
<div id="ref-coda" class="csl-entry">
Plummer, Martyn, Nicky Best, Kate Cowles, and Karen Vines. 2006.
<span>“CODA: Convergence Diagnosis and Output Analysis for MCMC.”</span>
<em>R News</em> 6 (1): 7–11. <a href="https://journal.r-project.org/archive/">https://journal.r-project.org/archive/</a>.
</div>
<div id="ref-USEPA09" class="csl-entry">
USEPA. 2009. <span>“Statistical Analysis of Groundwater Monitoring Data
at RCRA Facilities: Unified Guidance.”</span> Office of Resource
Conservation; Recovery, Program Implementation; Information Division,
U.S. Environmental Protection Agency, Washington, D.C.
</div>
<div id="ref-zellner1971bayesian" class="csl-entry">
Zellner, Arnold. 1971. <span>“Bayesian and Non-Bayesian Analysis of the
Log-Normal Distribution and Log-Normal Regression.”</span> <em>Journal
of the American Statistical Association</em> 66 (334): 327–30.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
